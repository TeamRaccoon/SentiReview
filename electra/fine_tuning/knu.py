# -*- coding: utf-8 -*-
"""Copy of KNU.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10GNFKjknq2jEDPcSGdVuKH6VOyc9-CHc
"""

!apt-get install g++ openjdk-8-jdk python-dev python3-dev
!pip3 install JPype1-py3
!pip3 install konlpy

!JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64"

import konlpy
from konlpy.tag import Kkma
from konlpy.utils import pprint
import json
import jpype
from tqdm import tqdm

class KnuSL():

	def data_list(wordname):
		#redirect path
		with open('./SentiWord_info.json', encoding='utf-8-sig', mode='r') as f:
			data = json.load(f)
		result = ['None','None']	
		for i in range(0, len(data)):
			if data[i]['word'] == wordname:
				result.pop()
				result.pop()
				result.append(data[i]['word_root'])
				result.append(data[i]['polarity'])	
		
		r_word = result[0]
		s_word = result[1]
							
		#print('어근 : ' + r_word)
		#print('극성 : ' + s_word)		
		
		
		return r_word, s_word

def read_data(file_path):
    with open(file_path, "r", encoding="utf8") as inFile:
        lines = inFile.readlines()

    datas = []
    for index, line in enumerate(tqdm(lines, desc="read_data")):
        # 입력 문장을 \t으로 분리
        pieces = line.strip().split("\t")

        # 데이터의 형태가 올바른지 체크
        assert len(pieces) == 3

        if(index == 0):
            continue

        id, sequence, label = pieces[0], pieces[1], int(pieces[2])
        datas.append((id, sequence, label))

    return datas

kkma = Kkma()
ksl = KnuSL

############여기###########
def knu_dict(review):
  words = konlpy.tag.Okt().pos(review, norm=True, stem=True)

  sum = 0
  predict = 0

  for word in words:
    data_list = ksl.data_list(word[0])
  
    try: sum += int(data_list[1])
    except: continue

  if sum>=0: predict = 1

  return predict